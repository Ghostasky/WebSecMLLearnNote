# 第三章 机器学习概述

本章介绍的数据集包括KDD 99、SEA、ADFA-LD等共10类，重点 介绍如何针对数字型和文本型的数据进行特征提取以及常见的数据读取 方式，最后介绍如何对机器学习的结果进行验证。

## 基本概念

-   有监督学习
-   无监督学习
-   准确率与召回率：召回率也叫查全率，准确率也叫查准率。

召回率=TP/（TP+FN） 准确率=TP/（TP+FP）

对于一个二分问题：

-   真正类（True positive，TP）：实例是实际为真 并且也被预测成真，
-   假正类（False positive，FP）：实际为假 被预测成真（误报）
-   真负类（True negative，TN）：实际 为假被预测成假，
-   假负类（false negative，FN）：实际为真被预 测成假（漏报）

## 数据集

### KDD 99数据

KDD是知识发现与数据挖掘（Knowledge Discovery and Data Mining）的简称

### HTTP DATASET CSIC 2010

HTTP DATASET CSIC 2010包含大量标注过的针对Web服务的 36000个正常请求以及25000个攻击请求，攻击类型包括sql注入、缓冲区 溢出、信息泄露、文件包含、xss等，被广泛用于WAF类产品的功能评 测。

### SEA数据集

SEA数据集涵盖70多个UNIX系统用户的行为日志，这些数据来自 于UNIX系统acct机制记录的用户使用的命令。SEA数据集中每个用户都 采集了15000条命令，从用户集合中随机抽取50个用户作为正常用户， 剩余用户的命令块中随机插入模拟命令作为内部伪装者攻击数据。

### ADFA-LD数据集

ADFA-LD数据集是澳大利亚国防学院对外发布的一套主机级入侵 检测系统的数据集合，被广泛应用于入侵检测类产品的测试。该数据集 包括Linux和Windows，记录了系统调用数据。

### Alexa域名数据

Alexa对外提供了全球排名 TOP一百万的网站域名的下载，文件是CSV格式，以排名、域名组成。

### Scikit-Learn数据集

Scikit-Learn自带的数据集合也十分经典，其中最常见的是iris数据 集。 iris中文指鸢尾植物，这里存储了其萼片和花瓣的长宽，一共4个属 性，鸢尾植物又分3类。与之相对，iris里有2个属性：iris.data和 iris.target。data里是一个矩阵，每一列代表了萼片或花瓣的长宽，一共4 列，一共采样了150条记录。target是一个数组，存储了data中每条记录 属于哪一类鸢尾植物，所以数组的长度是150，数组元素的值因为共有3 类鸢尾植物，所以不同值只有3个。

### MNIST数据集

MNIST是一个入门级的计算机视觉数据集，它包含各种手写数字图 片。



### Movie Review Data

Movie Review Data数据集包含1000条正面的评论和1000条负面评论，被广泛应用于文本分类，尤其是恶意评论识别方面。

### SpamBase数据集

入门级的垃圾邮件分类训练集。

### Enron数据集

机器学习领域使用Enron公司的归档邮件来研究文档分类、 词性标注、垃圾邮件识别等，由于Enron的邮件都是真实环境下的真实 邮件，非常具有实际意义。

## 特征提取

特征提取中数字型和文本型特征的提取最为常见。

### 数字型

#### 标准化

将特征数据的分布调整成标准正太分布，也叫高斯分布，也就是使得数据的均值维为0，方差为1.

```py
from sklearn import preprocessing
import numpy as np

x = np.array([[1., -1., 2.],
              [2., 0., 0.],
              [0., 1., -1.]])


x_scaled = preprocessing.scale(x)
print(x_scaled)
# 可以查看标准化后的数据的均值与方差，已经变成0,1了
a = x_scaled.mean(axis=0)
print(a)
# axis=1表示对每一行去做这个操作，axis=0表示对每一列做相同的这个操作
b = x_scaled.mean(axis=1)
print(b)
# 同理，看一下标准差
c = x_scaled.std(axis=0)
print(c)

[[ 0.         -1.22474487  1.33630621]
 [ 1.22474487  0.         -0.26726124]
 [-1.22474487  1.22474487 -1.06904497]]
[0. 0. 0.]
[ 0.03718711  0.31916121 -0.35634832]
[1. 1. 1.]
```

#### 正则化

正则化是将样本在向量空间模型上的一个转换，常用在分类和聚类中。

机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种，一般英文称作ℓ1-norm和ℓ2-norm，中文称作L1正则化和L2正则化，或者L1范数和L2范数。

L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择

L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合

```py
from sklearn import preprocessing
import numpy as np


X = [[1., -1., 2.],
     [2., 0., 0.],
     [0., 1., -1.]]
x_normalized = preprocessing.normalize(X)
print(x_normalized)

[[ 0.40824829 -0.40824829  0.81649658]
 [ 1.          0.          0.        ]
 [ 0.          0.70710678 -0.70710678]]
```

#### 归一化

归一化即使得特征的分布是在一个给定最小值和最大值的范围内的。一般情况是将其映射到[0,1]区间内，或者特征中绝对值最大的那个数为1，其他数以此为标准分布在[-1,1]内。

```py
from sklearn import preprocessing
import numpy as np


X = [[1., -1., 2.],
     [2., 0., 0.],
     [0., 1., -1.]]

min_max_scaler = preprocessing.MinMaxScaler()
x_minmax = min_max_scaler.fit_transform(X)
print(x_minmax)


[[0.5        0.         1.        ] 
 [1.         0.5        0.33333333] 
 [0.         1.         0.        ]]
```

